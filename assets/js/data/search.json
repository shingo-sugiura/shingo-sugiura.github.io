[ { "title": "Sampling Importance Resampling", "url": "/posts/sir/", "categories": "Math", "tags": "Note, Rendering, Sampling", "date": "2023-08-11 10:00:00 +0900", "snippet": "Sampling Importance Resampling(간단하게 Importance Resampling)은 임의의 분포로부터 샘플을 생성하는 알고리즘이다. 어떤 복잡한 분포든 evaluation만 가능하다면 그 분포에 근사하여 샘플을 생성할 수 있다.정규화 되지 않은(unnormalized) 분포 $ \\hat p $ 와 정규화된 분포(pdf) $p$를 생각해 보자.\\[\\frac{\\hat p}{C} = p\\]\\[C = \\int_{\\Omega} \\hat p(x) dx\\]앞으로 hat표시가 있는 $\\hat p$ 는 정규화 되지 않은 분포, $p$는 정규화된 분포(pdf)로 구분해서 표기하겠다.우리가 샘플링 하고싶은 target 분포는 정규화 되지 않은 $\\hat p(x)$ 이다.알고리즘SIR 알고리즘으로 $p$를 근사하여 샘플을 생성하는 알고리즘은 다음과 같다. 샘플링 하기 쉬운 source pdf $q$로부터 $M \\ge 1$ 개의 proposal 샘플을 생성한다. $\\mathbf{x} = \\{ x_1,…,x_M \\}$ 각 proposal 샘플마다 가충치 $w(x_i)$ 를 계산한다. $w(x) = \\frac{\\hat p(x)}{q(x)}$ proposal 샘플의 가중치에 비례한 확률로 샘플 $x_z$을 다시 뽑는다. (Resampling) $ p(z \\,|\\, \\mathbf{x}) = \\frac{w(x_z)}{\\sum_{i=1}^{M} w(x_i)},\\, z \\in \\{1,…,M\\} $ proposal 샘플의 가중치를 $w(x) = \\frac{\\hat p(x)}{q(x)}$ 로 설정한 부분이 핵심이다.proposal 샘플은 $q$를 따르는 샘플이므로 $\\mathbf{x}$에는 각 샘플이 $q(x_i)$에 비례한 만큼 존재한다. 여기서 가중치를 $q(x_i)$로 나눠줌으로써 이 시점에서 가중치($\\frac{1}{q(x_i)}$)에 비례해 Resampling하면 모든 샘플을 동일한 확률로 뽑게 만든다. 여기에 다시 $\\hat p(x)$ 을 곱하고 가중치 비례 Resampling을 하면 마침내 분포 $p$에 근사하여 샘플을 뽑을 수 있게 된다.proposal 샘플의 수 $M$을 분포 보간 변수(distribution interpolation variable)로 볼 수 있다. $M \\rightarrow \\infty$ 갈수록 샘플의 분포는 $q$에서 $p$로 수렴한다. 1번 레퍼런스 Figure 2.1RIS 논문에서 소개한 예시로 $q$는 uniform이고 $\\hat p = cos(\\theta) + sin^4(6\\theta)$ 일 때 $M$이 점점 커짐에 따라 Resampling의 분포가 uniform($q$) 에서 $p$로 점점 다가간다.SIR 알고리즘을 통해 생성된 샘플의 분포는 $q$와 $p$ 사이의 보간된, $p$에 근사하는 분포라는 부분을 잘 기억해야 한다. 정확히 $p$ 를 따르는 샘플이 아니다. 또한 SIR 알고리즘으로 생성된 샘플의 pdf는 알 수 없다. (논문에서 intractable 이라고 표현됨) 다시말해 resampling의 probability density는 unknown이다. ($M \\rightarrow \\infty$ 라면 $p(x_i)$ 다)source pdf $q$ 가 $p$ 와 모양이 비슷할수록 수렴 속도가 더 빨라진다.참조[1] https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=1662&amp;amp;context=etd[2] https://blog.demofox.org/2022/03/02/sampling-importance-resampling/[3] https://agraphicsguynotes.com/posts/understanding_the_math_behind_restir_di/#sample-importance-resampling-sir" }, { "title": "Multiple Importance Sampling", "url": "/posts/mis/", "categories": "Math", "tags": "Note, Rendering, Sampling", "date": "2023-08-08 02:00:00 +0900", "snippet": "Multi-sample Estimator바로 이전 포스트에서 Monte Carlo Estimator에 대해 알아봤다.\\[F_N = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{f(X_i)}{p(X_i)}\\]Estimator의 기댓값은 구하고자 하는 적분값이 되고, 이 결과는 편향이 없는(unbiased) 정확한 방법이다.\\[E[F_N] = \\int_{\\Omega} f(x) dx = I\\]이 Unbiased estimator 여러개에 대해 $\\sum_{i} w_i = 1$ 을 만족하는 weighted sum을 생각해 본다면\\[\\sum_{i=1}^{n} w_i E[F_i] = \\sum_{i=1}^{n} \\frac{1}{n_i} \\sum_{j=1}^{n_i} w_i E\\Big[\\frac{f(X_{i, j})}{p_i(X_{i, j})}\\Big] = I\\]여전히 unbiased하게 적분값을 추정할 수 있다. 여기서 기댓값의 선형성을 이용해 한번 더 나아가보면\\[E[F] = \\sum_{i=1}^{n} \\frac{1}{n_i} \\sum_{j=1}^{n_i} E \\Big[ w_i(X_{i,j}) \\frac{f(X_{i, j})}{p_i(X_{i, j})} \\Big] = I\\]심지어 가중치를 각 샘플에 dependent하도록 만들 수도 있다.이 Multi-sample Estimator가 unbiased하게 적분값을 추정하기 위해서는 다음 두 조건을 만족해야 한다. $f(x)$가 $0$이 아닐 때 $\\sum_{i=1}^{n} w_i(x) = 1$ $p_i(x)=0$ 일 때 $w_i(x) = 0$첫 번째 조건은 자명하고 두 번째 조건을 잘 생각해 보면 여러개의 Estimator가 있는데 어떤 Estimator $F_i$는 $f(x) \\ne 0$ 인 부분에서 $p_i(x)$가 $0$ 일 수도 있다는 뜻이고 $F_i$ 자체로는 Biased 되어있지만 다른 Estimator와의 결합으로 Unbiased한 적분 값을 추정하겠다는 의미다. $F_i$ 의 pdf $p_i$가 커버 못하는 적분 영역을 다른 Estimator의 pdf로 커버해야 할 테니 $w_i(x)$는 $0$이 되어야 한다.Balance Heuristic우리는 $N$개의 서로 다른 샘플링 전략을 갖는 Estimator를 잘 합칠수 있게 되었다. 이론적으로 $\\sum_{i} w_i = 1$을 만족하는 가중치 함수를 자유롭게 설정 할 수 있지만 가중치 함수를 잘못 설정하면 오히려 분산이 증가 할 수도 있게 되므로 가중치 함수를 적절히 구성해야 한다.가중치 함수에는 대표적으로 MIS 논문의 저자가 제안한 Balance Heuristic이 있다.\\[w_i(x) = \\frac{p_i(x)}{\\sum_{k}{p_k(x)}}\\]우선 가중치를 설정하는 방식을 보면 샘플링 전략 $p$가 어떤 임의의 샘플 $x$도 evaluate할 수 있어야 된다.샘플 $x$에 대한 $i$번째 샘플링 전략의 가중치를 위와 같이 설정한다는 것은, 만약 어떤 샘플링 전략 $p_i$가 샘플 $x$에 대해 높은 pdf 값을 갖는다면 바로 그 전략을 선호하겠다는 의미다.Balance Heuristic이 practical하게 잘 동작하기 위해선 피적분 함수의 서로 다른 부분을 잘 추정하는 샘플링 전략들을 합쳐서 Estimator를 구성하는 것이다. 렌더링 방정식을 예로 들어\\[L(\\mathbf{p}, \\omega_o) = \\int_{\\Omega} \\rho(\\mathbf{p}, \\omega_i, \\omega_o) L(\\mathbf{p}, \\omega_i) \\langle \\vec n_p \\cdot \\omega_i \\rangle \\, d\\omega_i\\]Estimator $F_1$은 BRDF와 Geometry term $\\rho \\, \\langle \\vec n_p \\cdot \\omega_i \\rangle$ 에 대한 샘플링 전략으로, $F_2$는 Incomming radiance $L(\\mathbf{p}, w_i)$에 대한 샘플링 전략으로 하여 두 Estimator를 합치면 의도한 대로 Balance Heuristic이 잘 동작할 것이다. (여기서 말하는 샘플링 전략은 Importance Sampling을 의미한다)Implementation Details실제로 Path tracer에 MIS을 적용한다면 NEE(Next Event Estimation)과 함께 사용된다. NEE에 따라 현재 hit point에서 Direct lighting을 추정 하는 부분을 MIS를 이용해 BRDF importance sampling과 Light sampling을 결합한다.Indirect lighting을 위해 다음 Ray direction을 설정 할 때는 BRDF에 Importance sample한 direction을 이용한다.아래는 MIS 논문의 레퍼런스 Scene을 내가 구현해본 결과다. 320x160, 64spp이다 BRDF sampling only Light sampling only Multiple Importance Sampling상단의 광원은 왼쪽에서 오른쪽으로 갈수록 커지고 plate는 아래에서 위로 갈수록 roughness값이 낮아진다.Material의 Roughness 값이 낮을수록 BRDF importance sampling이 유리하고, (plate의 우상단)반대로 Roughness 값이 높을수록 Light importance sampling이 유리하다. (plate의 좌하단)실제 MIS를 적용한 부분의 코드는 이곳 에서 확인 할 수 있다.참조[1] https://graphics.stanford.edu/papers/veach_thesis/thesis.pdf" }, { "title": "Monte Carlo Estimator", "url": "/posts/mce/", "categories": "Math", "tags": "Note, Rendering, Sampling", "date": "2023-08-02 23:00:00 +0900", "snippet": "Light Transport Simulation의 기본이 되는 Monte Carlo Estimator와 분산을 효과적으로 줄이는 기법인 Importance Sampling에 대해 알아보자.기댓값과 분산기댓값 Expected Value확률론에서 확률 변수의 기댓값이란 어떤 랜덤 프로세스를 반복했을 때 기대할 수 있는 값의 평균이다. 확률 변수 $X$의 기댓값은 $E[X]$로 쓴다. 이산 확률 변수의 기댓값은 다음과 같이,\\[E[X]_{X\\sim{p}} = \\sum_{i=1}^{n} {x_i} \\cdot p(x_i)\\]연속 활률 변수의 기댓값은 다음과 같이 정의된다.\\[E[X]_{X\\sim{p}} = \\int_{\\Omega} x \\cdot p(x) dx\\]예시주사위 던지기는 랜덤 프로세스다. 확률 변수 $X$ 가 주사위를 던져서 나온 숫자를 나타낸다고 생각해보자. 가능한 $X$ 는 $1, 2, 3, 4, 5, 6$ 이고 모든 값은 동일한 확률 $\\frac{1}{6}$ 로 발생한다. 따라서 이 랜덤 프로세스의 기댓값은 다음과 같이 계산할 수 있다.\\[E[X] = \\sum_{x=1}^{6} x \\cdot \\frac{1}{6} = 3.5\\]분산 Variance확률 변수의 분산은 각 변수들이 평균(기댓값)으로부터 얼마나 흩어져 있는지를 나타내는 지표다. 확률 변수 $X$의 분산은 $V[X]$로 쓰고 다음과 같이 정의된다.\\[V[X] = E[(X-E[X])^2]\\]예시주사위 던지기를 일반적인 주사위와 모든 면에 3.5가 적힌 주사위로 진행하면 두 경우 모두 기댓값은 3.5로 동일하겠으나 일반적인 주사위의 분산은\\[V[X] = \\sum_{x=1}^{6} (x - 3.5)^2 \\cdot \\frac{1}{6} = \\frac{17.5}{6} \\approx 2.9167\\]이고 모든 면이 3.5인 주사위는 0이다. 실제로 시행을 반복해 기댓값을 구하는 경우 분산이 작다면 몇번의 시행만으로 기댓값을 구할 수 있겠지만 반대로 분산이 아주 크다면 시행을 아주 많이 반복해야 기댓값에 수렴할 것이다.특성들기댓값과 분산의 정의에 따라 임의의 상수 $c$에 대해 다음이 만족한다.\\[\\begin{aligned} E[c \\, X] &amp;amp;= c \\, E[X] \\\\V[c \\, X] &amp;amp;= c^2 \\, V[X] \\\\\\end{aligned}\\]기댓값과 분산의 선형성에 따라 다음 등식도 만족한다. (분산의 경우 $X_i$가 서로 독립이어야 한다.)\\[\\begin{aligned} E \\Big[ \\sum_{i=1}^{N} X_i \\Big] =&amp;amp; \\sum_{i=1}^{N} E[X_i] \\\\V \\Big[ \\sum_{i=1}^{N} X_i \\Big] =&amp;amp; \\sum_{i=1}^{N} V[X_i] \\\\\\end{aligned}\\]위 특성들로 분산을 간단히 쓸 수 있다.\\[V[X] = E[(X-E[X])^2] = E[X^2] - E[X]^2\\]Monte Carlo Estimator우리는 적분값 $ I = \\int_{\\Omega} f(x) dx $ 을 수치적인 방법으로 구하고자 한다. 우선 고등학교때 배운 구분구적법(리만 합)을 적용한다면 다음과 같이 유한 합으로 적분 값을 추정할 수 있다. (x축 변이 균등하게 잘린 직사각형을 순서대로 모두 더하는 상황)\\[I \\approx \\frac{b-a}{N} \\sum_{i=1}^{N} f(x_i)\\]위 식을 균등 확률 변수(uniform random variable) $X_i \\in [a,b]$로 우항의 식을 Evaluation하는 랜덤 프로세스라고 보고 기댓값을 구해보자.\\[F_N = \\frac{b-a}{N} \\sum_{i=1}^{N} f(X_i)\\]\\[\\begin{aligned} E[F_N] &amp;amp;= E[\\frac{b-a}{N} \\sum_{i=1}^{N} f(X_i)] \\\\ &amp;amp;= \\frac{b-a}{N} \\sum_{i=1}^{N} E[f(X_i)] \\\\&amp;amp;= \\frac{b-a}{N} \\sum_{i=1}^{N} \\int_a^b f(x)p(x) dx \\\\&amp;amp;= \\frac{b-a}{N} \\sum_{i=1}^{N} \\int_a^b f(x) \\frac{1}{b-a} dx \\\\&amp;amp;= \\frac{1}{N} \\sum_{i=1}^{N} \\int_a^b f(x) dx \\\\&amp;amp;= \\int_a^b f(x) dx \\end{aligned}\\]결과적으로 이 랜덤 프로세스의 기댓값은 적분값이 된다.확률 분포 함수(pdf) $p(x)$ 가 uniform이라는 제약을 일반화 하면 Estimator를 다음과 같이 쓸 수 있다.\\[F_N = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{f(X_i)}{p(X_i)}\\]단, $ | f(x) | &amp;gt; 0$ 인 부분에서 $p(x) &amp;gt; 0$ 이어야 한다. 이 식이 적분값이 되는지 간단히 확인해 보면,\\[\\begin{aligned} E[F_N] &amp;amp;= E[\\frac{1}{N} \\sum_{i=1}^{N} \\frac{f(X_i)}{p(X_i)}] \\\\ &amp;amp;= \\frac{1}{N} \\sum_{i=1}^{N} E[\\frac{f(X_i)}{p(X_i)}] \\\\&amp;amp;= \\frac{1}{N} \\sum_{i=1}^{N} \\int_{\\Omega} \\frac{f(x)}{p(x)} p(x) dx \\\\&amp;amp;= \\frac{1}{N} \\sum_{i=1}^{N} \\int_{\\Omega} f(x) dx \\\\&amp;amp;= \\int_{\\Omega} f(x) dx \\end{aligned}\\]분산 감소 기법Monte Carlo Estimator를 이용해 적분 값을 추정하는 과정은 시행을 반복해 기댓값을 수치적으로 구하는 과정이다. 우리는 이 랜덤 프로세스의 분산을 생각할 수 있다. Estimator의 분산은 이미지에 노이즈로 나타나게 되고 곧 렌더링 품질을 가른다. 따라서 렌더링에서 Estimator의 분산을 줄이는 작업은 매우 중요하고 렌더링 기법의 발전이 분산을 줄이는 과정이라고 말해도 과언이 아니다.Monte Carlo Estimator의 분산을 분석하고 분산을 감소시키는 대표적인 기법인 Importance Sampling을 알아보자.분산 분석분산의 정의에 따라 Estimator의 분석을 계산해 보면\\[\\begin{aligned} V[F_N] &amp;amp;= V[\\frac{1}{N} \\sum_{i=1}^{N} \\frac{f(X_i)}{p(X_i)}] \\\\ &amp;amp;= \\frac{1}{N^2} \\sum_{i=1}^{N} V[\\frac{f(X_i)}{p(X_i)}] \\\\ &amp;amp;= \\frac{1}{N} V[\\frac{f(X)}{p(X)}] \\\\\\end{aligned}\\]위 식을 통해 $N$에 따라 선형적으로 분산이 감소한다는 것을 알 수 있고,\\[\\sigma [F_N] = \\frac{1}{\\sqrt{N}} \\sigma \\Big[\\frac{f(X)}{p(X)} \\Big]\\]표준편차로부터 RMS(Root Mean Square; 평균 제곱근) Error는 $O(N^{0.5})$ 의 속도로 수렴함을 알 수 있다. (absolute error의 수렴 속도를 분석하는 부분은 3번째 레퍼런스 2.4.1을 참고해 주세요. 이는 마찬가지로 $O(N^{0.5})$ 입니다. )Monte Carlo Estimator의 유일한 약점(?)이 수렴 속도가 $O(N^{0.5})$ 으로 꽤 느리다는 것인데, 이 문제를 해결하기 위해 다양한 분산 감소 기법을 사용한다.Importance SamplingImportance Sampling을 통한 분산 감소의 핵심은 샘플을 생성하는 확률 분포 함수 $p$를 우리가 자유롭게 선택할 수 있다는 부분에 있다.단적인 예시로 $p$를 피적분 함수 $f$ 에 비례하게 설정하는 경우를 생각해보자. $p \\propto f,\\, p(x) = cf(x)$. 확률 분포 함수는 정규화($\\int_{\\Omega} p(x) dx = 1$) 되어야 하기 때문에\\[c = \\frac{1}{\\int_{\\Omega} f(x)dx}\\]그러나 이러한 확률 분포 함수는 우리가 처음에 추정하려던 적분의 값을 알아야 한다. 결국 처음 풀고자 하는 문제로 돌아온 셈이다. 그럼에도 불구하고 만약 이런 확률 분포 함수로부터 샘플링하는 경우를 생각해 본다면,\\[\\frac{f(X_i)}{p(X_i)} = \\frac{1}{c} = \\int f(x) dx\\]언제나 한번의 evaluation 만으로 적분 값을 추정할 수 있게 될 것이다. 즉 분산이 0인 것이다.\\[\\begin{aligned}V[F_N] &amp;amp;= \\frac{1}{N} V[\\frac{f(X)}{p(X)}] \\\\&amp;amp;= \\frac{1}{N} V[\\frac{1}{c}] \\\\&amp;amp;= 0\\end{aligned}\\]물론 위 방식이 practical 하지는 않지만, $f$와 모양(Shape)이 비슷한 pdf $p$를 선택하면 Estimator의 분산은 감소한다.정리하자면 Importance Sampling의 기본적인 아이디어는 피적분 함수값이 큰 부분에 샘플링을 많이 해서 분산을 줄이자는 내용이다. 당연히 피적분 함수값이 큰 부분은 결과에 크게 기여하고 함수값이 작은 부분은 적게 기여할 것이다.일반적인 경우 피적분 함수 $f$의 특정 factor에 대해 Importance Sampling하는 식으로 많이 쓰인다. 예를 들어 렌더링 방정식의 경우 BRDF와 Geometry term에 대해 Importance Sampling해서 해당 항으로 부터 나오는 분산을 줄인다. 특정 factor에 대한 정확한 샘플링 루틴이 존재하는 경우 Evaluation 단계에서 해석적으로 해당 항을 약분할 수도 있다.정리 우리는 Monte Carlo Estimator를 이용해 어떠한 함수의 적분값도 랜덤 프로세스로 추정할 수 있다. Estimator의 분산을 줄이기 위해 Importance Sampling 같은 분산 감소 기법을 사용한다.참조[1] https://www.pbr-book.org/3ed-2018/Monte_Carlo_Integration/The_Monte_Carlo_Estimator[2] https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=1662&amp;amp;context=etd[3] https://www.ime.usp.br/~jmstern/wp-content/uploads/2020/04/EricVeach2.pdf" }, { "title": "Weighted Reservoir Sampling", "url": "/posts/wrs/", "categories": "Math", "tags": "Note, Rendering, Sampling", "date": "2023-07-31 23:00:00 +0900", "snippet": "문제 설명어떤 데이터 $ E_i \\, (1 \\le i \\le N) $ 스트림이 있는데 시점 $t$ 에 $E_t$ 를 볼 수 있고 스트림의 총 길이 $N$ 은 미리 알 수 없다. 각 $E_i$ 에 가중치 $w_i$ 가 주어지고 우리는 가중치에 비례해 데이터를 샘플링 하고 싶다.즉, 총 가중치 $ W = \\sum_{k \\le N} w_k $ 로 모든 데이터를 본 시점에 랜덤한 샘플 $ E_j $ 를 $ w_j / W $ 의 확률로 뽑고자 한다.Weighted Reservoir SamplingWeighted Reservoir Sampling 알고리즘은 현재 선택된 샘플 $R$ 과 가중치 합 $w_{sum}$ 을 저장하는 Reservoir $\\mathcal{R} = \\{ R,\\,w_{sum} \\} $ 를 들어오는 데이터에 대해 순차적으로 업데이트하는 방식으로 동작한다.알고리즘Reservoir를 초기화한다.$\\mathcal{R} \\leftarrow \\{ \\emptyset,\\, 0 \\} $스트리밍 데이터 $E_i$ 와 해당 가중치 $w_i$를 가지고 다음의 함수를 통해 Reservoir를 업데이트한다.$\\textbf{update}(\\,E_i,\\,w_i\\,):$$\\qquad w_{sum} \\leftarrow w_{sum} + w_i $$\\qquad \\zeta \\leftarrow rand() $ // $\\text{uniform random [0…1]}$$\\qquad \\textbf{if}\\, (\\, \\zeta &amp;lt; w_i / w_{sum\\,} ):$$\\qquad\\qquad R \\leftarrow E_i $수학적 증명위 알고리즘이 원하는대로 동작하는지, 즉 N개의 데이터를 처리했을 때 $ w_j / \\sum_{k \\le N} $ 의 확률로 $E_j$를 샘플링 한게 맞는지 귀납적으로 증명해보자.우선 N=1 인 경우 $E_1$을 $w_1/w_1 = 1$ 의 확률로 선택한다. ($w_1$가 0인경우 0의 확률로 선택)스텝 $i$에서 $E_i$ 를 처리하기 전에 현재 Reservoir가 $E_j$ 를 $w_j / \\sum_{k &amp;lt; i} w_k$ 의 확률로 선택하여 $ \\{ E_j,\\,\\sum_{ k &amp;lt; i w_k} \\}$ 인 상태라고 가정하자.위 업데이트 알고리즘에 따라 $E_i$는 다음의 확률로 선택된다.\\[\\frac{w_i}{\\Sigma_{k &amp;lt; i} w_k + w_i} = \\frac{w_i}{\\Sigma_{k \\le i} w_k}\\]반대로 기존의 선택된 샘플 $E_j$는 다음의 확률로 Reservoir에 남는다.\\[1 - \\frac{w_i}{\\Sigma_{k &amp;lt; i} w_k + w_i} = \\frac{(\\Sigma_{k \\le i} w_k) - w_i}{\\Sigma_{k \\le i} w_k} = \\frac{\\Sigma_{k &amp;lt; i} w_k}{\\Sigma_{k \\le i} w_k}\\]$E_j$가 기존에 $w_j / \\sum_{k &amp;lt; i} w_k$의 확률로 선택되어 있었고 스탭 $i$가 처리되면 $E_j$는 최종적으로 다음과 같은 확률로 선택된다.\\[\\Big( \\frac{w_j}{\\Sigma_{k &amp;lt; i} w_k} \\Big) \\Big( \\frac{\\Sigma_{k &amp;lt; i} w_k}{\\Sigma_{k \\le i} w_k} \\Big) = \\frac{w_j}{\\Sigma_{k \\le i} w_k}\\]결과적으로 $E_i$ 또는 $E_j$가 정확한 확률로 선택되게 된다.Reservoir 합치기Reservoir $ \\mathcal{R_1} $ 이 $ \\{ E_i,\\, \\Sigma_{k \\le n} w_k \\} $ 인 상태이고 $ \\mathcal{R_2} $ 가 $ \\{ E_j,\\, \\Sigma_{k \\le m} w_k \\} $ 인 상태를 생각해보자. 두 Reservoir는 각각 $E_i,\\, E_j$ 를 $ w_i / \\Sigma_{k \\le n} w_k $, $ w_j / \\Sigma_{k \\le m} w_k $ 의 확률로 샘플링한 정상적인 상태다.Reservoir $ \\mathcal{R_1} $ 에 대해 $ \\mathcal{R_2}.R $ 과 $\\mathcal{R_2}.w_{sum}$ 으로 업데이트 함수를 호출하면 어떻게 될까 ?$ \\mathcal{R_2} $ 의 샘플 $E_j$ 가 다음의 확률로 선택되거나\\[\\Big( \\frac{w_j}{\\Sigma_{k \\le m} w_k} \\Big) \\Big( \\frac{\\Sigma_{k \\le m} w_k}{\\Sigma_{k \\le n} w_k + \\Sigma_{k \\le m} w_k} \\Big) = \\frac{w_j}{\\Sigma_{k \\le n} w_k + \\Sigma_{k \\le m} w_k}\\]$ \\mathcal{R_1} $ 의 샘플 $E_i$ 가 다음의 확률로 선택된다.\\[\\Big( \\frac{w_i}{\\Sigma_{k \\le n} w_k} \\Big) \\Big(1 - \\frac{\\Sigma_{k \\le m} w_k}{\\Sigma_{k \\le n} w_k + \\Sigma_{k \\le m} w_k} \\Big) = \\Big( \\frac{w_i}{\\Sigma_{k \\le n} w_k} \\Big) \\Big( \\frac{\\Sigma_{k \\le n} w_k}{\\Sigma_{k \\le n} w_k + \\Sigma_{k \\le m} w_k} \\Big) = \\frac{w_i}{\\Sigma_{k \\le n} w_k + \\Sigma_{k \\le m} w_k}\\]결과적으로 어떤 Reservoir의 결과 샘플과 가중치의 합으로 다른 Reservoir를 업데이트하는 과정은 독립적인 두 스트리밍 데이터를 모두 보고 샘플링한 결과와 동일하다. 샘플 $\\{ E, w \\}$ 을 데이터 1개를 처리한 Reservoir로 취급할 수 있다.결론 Weighted Reservoir Sampling은 길이를 알 수 없는 스트리밍 데이터에 대해 공간 복잡도 O(1)으로 가중치 샘플링을 할 수 있다. 각 데이터를 처리하는 과정은 시간복잡도 O(1)이다. 독립적으로 진행된 두 샘플링 결과를 쉽게 합칠수 있다. (분할 정복)참조http://cwyman.org/papers/rtg2-chapter22-preprint.pdfhttps://agraphicsguynotes.com/posts/understanding_the_math_behind_restir_di/#weighted-reservoir-sampling-wrs" }, { "title": "Quaternion differentiation", "url": "/posts/quaternion-integration/", "categories": "Math", "tags": "Note", "date": "2023-02-27 22:00:00 +0900", "snippet": "[!] 이 문서에서 사용되는 \\vec 표기는 벡터가 아니라 pure quaternion입니다. 예를 들어 $\\vec w$는 $ 0 + w_x i + w_y j + w_z k $ 형태의 사원수. 또한 \\hat은 표기는 unit quaternion 입니다.[!] 아래 유도 과정을 이해 하기 위해선 사원수에 대한 이해가 필요합니다.Intro\\[\\hat q_{new} = \\hat q_{old} + \\frac 1 2 \\vec w \\hat q_{old} \\Delta t\\]Angular velocity vector를 사원수 orientation에 적용(수치 적분) 하는 방법을 찾다가 위와 같은 식 발견했는데 많은 사람들이 유도 과정에 대한 이해는 생략하고 black box formula 처럼 사용하는듯 했다..Quaternion differentiation$\\hat q(t)$가 $t$ 에서의 rotation quaternion이고, $\\hat r$은 unit time에 대한 rotational motion 이라고 생각한다면,\\[\\hat q(0)=\\hat q_0\\]\\[\\hat q(t)=\\hat r^t \\hat q_0\\]위와 같이 쓸 수 있다.unit quaternion $\\hat r$은 오일러 공식을 이용해 아래와 같이 지수 함수로 표현 할 수 있다.\\[\\hat r=e^{\\frac \\theta 2 \\vec u}\\]여기서 $\\vec u$는 실수 부분이 0이고 벡터 파트는 회전축 단위 벡터인 pure quaternion 이다.\\[\\vec u = u_x i + u_y j + u_z k\\]오일러 공식을 테일러 급수를 이용해 유도 할 때 $e^x$의 x 자리에 $i$를 넣어 유도하는 부분을 기억하자. 허수 단위 $i$가 제곱해서 -1이 되듯 pure quaternion $\\vec u$도 제곱하면 -1이 된다. 즉 대수적 성질이 동일하다.\\[\\hat r^t=exp(\\frac \\theta 2 \\vec u t)\\]\\[\\hat q(t)=exp(\\frac \\theta 2 \\vec u t)\\hat q_0\\]양변을 미분하면,\\[\\hat q&#39;=\\frac \\theta 2 \\vec u exp(\\frac \\theta 2 \\vec u t)\\hat q_0\\]\\[\\hat q&#39;=\\frac \\theta 2 \\vec u \\hat q\\]여기서 $ \\theta \\vec u $는 각속도 pure quaternion $\\vec w$ 이기 때문에\\[\\hat q&#39;=\\frac 1 2 \\vec w \\hat q\\]위와 같은 미분방정식을 얻게 된다.Integration이제 각속도와 Orientation에 대한 미분 방정식이 주어졌으니, 일반적인 방법대로 수치적분을 하면 된다.\\[\\frac {\\Delta \\hat {q}} {\\Delta t} \\approx \\frac 1 2 \\vec w \\hat q_0\\]\\[{\\Delta \\hat {q}} \\approx \\frac 1 2 \\vec w \\hat q_0 {\\Delta t}\\]\\[\\hat q_1 \\approx \\hat q_0 + \\frac 1 2 \\vec w \\hat q_0 {\\Delta t}\\]여느 수치 적분법이 그렇듯 $\\Delta t$가 크면 오류도 커진다. 더군다나 orientation을 나타내는 quaternion은 unit quaternion이어야 하기 때문에, 오류를 고려하여 시뮬레이션 중에 orientation을 renormalization하는 작업이 필요하다.Referenceshttps://en.wikipedia.org/wiki/Quaternionhttps://en.wikipedia.org/wiki/Quaternions_and_spatial_rotationhttps://gamedev.stackexchange.com/questions/108920/applying-angular-velocity-to-quaternion" }, { "title": "멤버 변수 오프셋과 정렬", "url": "/posts/struct-member-offset/", "categories": "Programming, C++", "tags": "Note, Programming, C++", "date": "2022-08-02 20:10:00 +0900", "snippet": "Offset and alignment of member variables, 멤버 변수 오프셋과 정렬멤버 변수의 offset다음과 같은 구조체가 있을때 각 멤버 변수의 offset(메모리 상에서 해당 변수가 시작하는 지점)을 컴파일 타임에 구하고자 한다.struct VertexLayout{ float position[3]; float normal[3]; float uv[2];};위와 같은 구조체에서 각 멤버 변수의 offset을 생각해 본다면 직관적으로 position은 0, normal은 position 12, uv는 24 일것이다. 구조체 전체 사이즈는 32바이트. float은 4바이트고 메모리상에 변수들이 연속적으로 위치해 있으므로 이 생각이 실제로도 맞다.다음의 코드로 멤버 변수의 offset 값을 코드로 컴파일 타임에 계산할 수 있다.size_t offset = (size_t) &amp;amp;((VertexLayout*)nullptr)-&amp;gt;normal;해석해 보자면 nullptr, 즉 (void*)0 을 offset을 구하고자 하는 구조체 포인터로 형변환 한다 1번에서 구한 포인터에 -&amp;gt; 로 특정 멤버값을 얻어 오고 &amp;amp; 로 그 멤버의 주소를 얻는다. 그 주소는 0번지에서 시작된 값이므로 그 주소값 자체가 해당 멤버 변수의 offset이 된다.간결하고 멋진 방법으로 구조체의 멤버 변수의 offset을 계산하는 코드다!나아가서 해당 코드를 아래와 같이 매크로로 만들 수 있다.#define OffsetOf(T, m) (size_t)&amp;amp;((T*)nullptr)-&amp;gt;m - (size_t)nullptr// 호출 할 때는 이런식으로..OffsetOf(VertexLayout, normal);위 코드에서 (size_t)nullptr를 빼주는 이유는 nullptr가 물론 (void*) 0 로써 0번지를 가리키는 값 이겠지만 명시적어놔 봤다. nullptr 대신 임의의 위치에서 시작한다면 해당 빼기 연산을 꼭 해줘야 할 것이다.cstddef 헤더에 같은 동작을 하는 offsetof() 매크로가 있다.아래는 c++스럽게 매크로를 이용하지 않고 템플릿을 이용해 OffsetOf 매크로와 동일한 동작을 하는 코드다.template&amp;lt;typename T, typename U&amp;gt;constexpr size_t offsetOf(U T::* m){ return (size_t)&amp;amp;(((T*)nullptr)-&amp;gt;*member) - (size_t)nullptr;}// 호출 할 때는 이런식으로..offsetOf(&amp;amp;VertexLayout::normal);Member variable alignment, 멤버 변수 정렬위 VertexLayout 구조체의 경우는 멤버 변수들이 연속적으로 메모리 상에 위치해 있는다. 아래와 같은 경우라면 멤버 변수가 메모리 상에 어떤식으로 정렬(align) 되어 있을까?struct T{ int a; // 4 bytes bool b; // 1 byte float c; // 4 bytes double d; // 8 bytes};VertexLayout 구조체처럼 모든 멤버가 연속적으로 존재해서 offset들이 a는 0, b는 4, c는 5, d는 9 일까? 실제로 OffsetOf로 찍어보면..int main(){ printf(&quot;%d &quot;, OffsetOf(T, a)); printf(&quot;%d &quot;, OffsetOf(T, b)); printf(&quot;%d &quot;, OffsetOf(T, c)); printf(&quot;%d &quot;, OffsetOf(T, d)); printf(&quot;\\n%d&quot;, sizeof T); return 0;}// 출력 결과// 0 4 8 16// 24결과는 예상과 다르게 나왔다. 그 이유는 컴파일러가 최적화를 위해 멤버 사이에 패딩(padding)을 넣었기 때문이다. 규칙은 아래와 같다.컴파일러는 멤버 변수가 메모리 상에서 구조체의 시작점을 기준으로 각 멤버 변수 바이트 크기의 배수 주소에서 변수가 위치되도록 패딩을 넣는다. 또한 구조체 사이즈가 멤버 변수중 가장 바이트수가 큰 놈의 배수로 끝나도록 마지막에 패딩을 넣는다.위 T 구조체로 예로 들면 다음과 같다. a는 0번지에서 4바이트 차지 -&amp;gt; offset = 0 b는 4번지에서 1바이트 차지 -&amp;gt; offset = 4 c는 float이므로 4바이트 즉 4의 배수 지점에서 시작 되어야 하기 때문에 가장 가까운 배수, 8번지에서 4바이트 차지 -&amp;gt; offset = 8 5, 6, 7 번지는 padding이 들어감 d는 double이므로 8바이트 즉 8의 배수 지점에서 시작 되어야 하기 때문에 가장 가까운 배수 16번지에서 8바이트 차지 -&amp;gt; offset = 16 12, 13, 14, 15 번지는 padding이 들어감 멤버 변수중 바이트가 제일 큰 놈은 8바이트이고 현제 구조체가 8의 배수 24에서 딱 끝나기 때문에 뒷쪽에 padding을 넣지 않는다. -&amp;gt; size = 24bytes이런 규칙대로 컴파일러는 구조체 멤버 사이사이에 패딩을 넣는데 그 이유는 CPU 메모리 엑세스 패턴과 관련하여 최적화 하기 위함이라고 한다. 위와 같이 잘 데이터가 정렬되어 있으면 naturally aligned 라고 표한하고 아니라면 misaligned 라고 표현 한다고 한다. misaligned된 데이터도 동작하긴 하지만 퍼포먼스 차이가 상당하다.(정말로 심하게 차이난다) 그러므로 pragma pack 같은 전처리 지시자를 이용해서 packing, alignment를 프로그래머가 컨트롤 할 수도 있지만 메모리가 정말 부족한 환경이 아니라면 그대로 두는게 좋다. https://docs.microsoft.com/en-us/cpp/cpp/alignment-cpp-declarations?view=msvc-170정리Alignment 내용과 관련해서 중요한 부분은 위에 적힌 규칙이 일반적이지만 컴파일러마다 다를 수 있고 같은 컴파일러를 써도 컴파일하는 환경마다 다를수 있다는 것이다.그래서 동일한 로컬 머신에서 구조체 또는 객체를 serialization해서 파일에 썻다가 불러오는것 같은 경우는 간단하게 바이너리로 write하고 memcpy로 불러오는 식으로 빠르게 처리할 수 있겠지만, 저장된 파일이 다른 환경에서 불러와 지는 경우라면 위 내용들을 고려해야 될 것이다." }, { "title": "Constraints in physics engine", "url": "/posts/constraints-in-physics-engine/", "categories": "Programming, Physics", "tags": "Physics, Physics Engine", "date": "2022-03-01 08:50:00 +0900", "snippet": "이 글은 메모글 입니다. 처음 읽으시는 분들은 이해하기 힘듭니다..Constraint in physics engine물리엔진에서는 모든 것들을 constraint(제약)로 정의한다.추상적인 위 문장을 좀 더 자세히 풀어서 설명하자면 다음과 같다.우리는 어떤 시스템을 만드는데, 이 시스템을 구성하는 요소들을 constraint로 정의하고 이 시스템의 모든 constraint가 만족(satisfied)된 상태라면 이 시스템은 문제가 없는 상태라고 본다. 반면 어떤 constraint가 위반(violated)되었다면 그것을 해결(solve)하여 문제가 없는 상태로 만든다.물리엔진은 이 시스템을 우리가 사는 세계처럼 물리적으로 옳게 보이는 constraint들을 하나 하나 정의하여 만든다. 예를 들어 어떤 강체(Rigid body)가 움직이다가 다른 강체와 겹쳐지는 상황을 생각해 보자. 아무런 constraint도 없는 시스템이라면 이런 상황은 문제될게 없다. 반면 non-penetration constraint가 정의된 시스템(물리엔진)이라면 이 상황은 문제되는 상황이고 이를 적절하게 해결해야 한다.Modeling and solving constraint어떤 오브젝트의 position 정보 $q$를 이용하여 position constraint, $C(q)=0$를 정의한다.$C$를 미분하여 velocity constraint, $\\dot{C} = Jv$을 구한다.여기서 $J$는 jacobian matrix다. $( \\dot{C} = \\frac{\\partial{C}}{\\partial{q}} \\dot{q}) $$\\bar v_2 = v_1 + M^{-1} \\cdot F_{ext} \\cdot \\Delta t$위 식에서 $\\bar v_2$ 는 이전 프레임에서의 속도 $v_1$에 외력 $F_{ext}$를 적용하여 잠재적으로 velocity constraint를 위반한 상태인 속도 벡터이다. 즉 $v_1$에 외력을 적용한 tentative velocity $\\bar v_2$를 solve하여 velocity constraint를 만족하게 되는 $v_2$를 계산한다.$v_2 = \\bar v_2 + M^{-1} \\cdot P_c = \\bar v_2 + \\Delta V_c$위 식에서 $P_c$는 corrective impulse이다. 해석하자면 tentative velocity 에 적절한 impulse를 가해서 constraint가 만족하도록 만든다는 것이다.$P_c = J^T \\lambda\\;(\\because P_c \\parallel J^t)\\;$ 여기서 $\\lambda$ 는 Lagrangian multiplier이 부분이 constraint solve 과정에서 가장 이해하기 힘든 부분이다. 어째서 corrective impulse의 방향이 $J^T$인 것인가..아주 간단하고 직관적으로 설명하자면, 시스템에서 constraint는 passive하기 때문에 constraint force(impulse)는 일을 하지 않아야 하기 때문에 $v$에 수직인 $J^T$와 평행한 방향이어야 한다는 것이다.자 이제 corrective impulse의 방향은 알았으니 그 크기 $\\lambda$ 를 구하면 된다.$Jv_2 + b = 0\\;(\\because \\dot C = Jv+b = 0)$$J(\\bar v_2 + M^{-1} \\cdot P_c) + b = 0$$J(\\bar v_2 + M^{-1} \\cdot J^T \\lambda) + b = 0$$J\\bar v_2 + J \\cdot M^{-1} \\cdot J^T \\cdot \\lambda + b = 0$$\\lambda = (J M^{-1} J^T)^{-1} \\cdot -(J\\bar v_2 + b)$$P_c = J^T \\cdot (J M^{-1} J^T)^{-1} \\cdot -(J\\bar v_2 + b)$$\\therefore v_2 = \\bar v_2 + M^{-1} \\cdot J^T \\cdot (J M^{-1} J^T)^{-1} \\cdot -(J\\bar v_2 + b)$Conclusion물리엔진은 정말 모든것을 constraint로 정의한다. 위에서 언급한 non-penetration constraint뿐만 아니라 다양한 관절(joint)들 심지어 모터, 도르래 같은 것들도 모두 다 constraint로 정의한다. 또한 constraint마다 jacobian $J$ 만 다르기 때문에 solve 과정이 모든 constraint에 대해 일관적(unified way)이다.이 글에서 정리한 내용은 물리엔진 constraint에 대한 내용 속에서 핵심적인 내용이긴 하지만 아주 일부이다. 언급 안한 bias $b$ 에도 많은 내용이 숨겨져 있다.. positional error correction, soft constraint 등등.. 또한 왜 acceleration 레벨이 아닌 velocity 레벨에서 impulse로 constraint를 해결하는지 등등 이러한 내용들도 다 정확히 이해해야 한다.기회가 된다면 물리엔진 튜토리얼 글을 쓰고 싶다." }, { "title": "Random, 랜덤", "url": "/posts/random/", "categories": "Programming, Note", "tags": "Note", "date": "2022-01-18 23:30:00 +0900", "snippet": "True random vs. Pseudo random컴퓨터 공학을 포함한 여러 다양한 분야에서 난수(Random numbers)는 중요합니다. 일단 ‘랜덤한 숫자’라는 의미 자체로 여러 곳에서 사용될 수 있을 것입니다.그런데 사실 대부분의 컴퓨터 프로그램에서 사용하는 랜덤들은 진짜 난수(True random numbers)가 아니고 의사 난수(Pseudo random)입니다. True random은 우리가 직관적으로 생각하는 이상적인 랜덤이고, Pseudo random은 특정한 수식을 통해 정의되는 수열을 통해 얻게되는 값(fake random)입니다.True randomrandom.org 에서 제공하는 랜덤 값은 대기의 노이즈를 이용하기에 True randomness를 보장한다고 합니다.수학적으로 True random number generator를 모델링 할 수 없기 때문에 True random을 보장하기 위해서는 random.org에서 사용하는 방법처럼 예측 불가능한(랜덤이라고 보여지는) 물리 현상을 관측하고, 관측 결과를 적절히 후처리한 값을 이용해야 합니다. 또는 아래에 소개할 PRNG를 이용하되, 주기적으로 얻어온 True random 값을 이용해 re-seeding 하여 이용하는 하이브리드한 방법도 있습니다.관측에 이용되는 물리현상에는 다양한것들이 있을 수 있습니다. 더 자세한 내용은 아래 레퍼런스를 참고해주세요.random.org는 http api도 제공합니다. 아래 커맨드 라인에서 curl을 이용한 예제를 확인해 보세요.curl &quot;https://www.random.org/integers/?num=10&amp;amp;min=1&amp;amp;max=100&amp;amp;col=1&amp;amp;base=10&amp;amp;format=plain&amp;amp;rnd=new&quot;Pseudo random의사 난수 생성(Pseudo random generation)이란 특정한 수식을 이용해 일정한 주기를 가지는 랜덤한 수열을 만드는 방법입니다. 아래 수식과 같이 선형 함수와 mod 연산을 이용해 빠른 속도로 pseudo random number를 만들어내는 방법도 있고 비슷한 형식으로 XOR과 Shift를 이용한 방법도 있습니다.\\[X_{n+1} = a(X_n + c)\\,mod\\,m\\]주목해야 할 점은 PRNG 수식을 구성하는 상수들이 같다면 언제나 같은 수열을 만들 수 있다는 점 입니다. 이런 특징을 seedable 하다고 하며 이는 PRNG의 중요한 속성입니다.Code아래는 제가 사용했던 PRNG들 입니다.// https://en.wikipedia.org/wiki/Linear_congruential_generator class PRNG { constructor(seed) { this.m = 0x80000000; // 2^31; this.a = 1103515245; this.c = 12345; this.state = (seed != undefined) ? seed : Math.floor(Math.random() * (this.m - 1)); } nextInt() { this.state = (this.a * this.state + this.c) % this.m; return this.state; } nextFloat() // 0.0 ~ 1.0 { return this.nextInt() / (this.m - 1); }}// www.cs.ubc.ca/~rbridson/docs/schechter-sca08-turbulence.pdfuint hash(uint state){ state ^= 2747636419u; state *= 2654435769u; state ^= state &amp;gt;&amp;gt; 16; state *= 2654435769u; state ^= state &amp;gt;&amp;gt; 16; state *= 2654435769u; return state;}#include &amp;lt;cstdint&amp;gt;// Period: 2^128 - 1uint64_t xor128(){ static uint64_t x = 123456789; static uint64_t y = 362436069; static uint64_t z = 521288629; static uint64_t w = 88675123; uint64_t t; t = x ^ (x &amp;lt;&amp;lt; 11); x = y; y = z; z = w; return w = w ^ (w &amp;gt;&amp;gt; 19) ^ t ^ (t &amp;gt;&amp;gt; 8);}아래는 메르센 트위스터(Mersenne twister) 알고리즘을 이용해 난수를 생성하는 c++ 코드.PRNG중에 가장 복잡하지만 주기가 무려 $2^{19937} - 1$. 반복 주기가 메르센 소수인것이 이름의 유래라고 합니다.#include &amp;lt;iostream&amp;gt;#include &amp;lt;random&amp;gt;int main(){ std::random_device rd; std::mt19937 mt(rd()); std::uniform_int_distribution&amp;lt;int&amp;gt; ud(0, 100); for (int i = 0; i &amp;lt; 100; i++) std::cout &amp;lt;&amp;lt; ud(mt) &amp;lt;&amp;lt; std::endl; return 0;}Referenceshttps://en.wikipedia.org/wiki/Random_number_generation#%22True%22_vs._pseudo-random_numbers" }, { "title": "Rotating reference frame", "url": "/posts/Rotating-reference-frame/", "categories": "Math", "tags": "Note", "date": "2022-01-08 09:50:00 +0900", "snippet": "Relating rotating frames to stationary frames기저벡터 $\\hat{i},\\,\\hat{j}$ 그리고 $\\frac{d(\\theta)}{dt} = w,\\,\\theta(t) = wt + \\theta_0$$z$축으로 회전한다고 했을시,$\\hat{i}(t) = (cos\\theta(t), -sin\\theta(t))$$\\hat{j}(t) = (sin\\theta(t), cos\\theta(t))$이 기저벡터들의 시간에 대한 미분은,$ \\frac{d}{dt}\\hat{i}(t) = w(-sin\\theta(t), -cos\\theta(t)) = -w\\hat{j}$$ \\frac{d}{dt}\\hat{j}(t) = w(cos\\theta(t), -sin\\theta(t)) = w\\hat{i}$곧 $ \\frac{d}{dt}\\hat{u} = \\Omega\\times\\hat{u}\\,\\,(\\hat{u}= \\hat{i}\\,or\\,\\hat{j},\\,\\Omega = (0, 0, w))$Time derivatives in the two frames$\\mathit{f}\\,$가 아래와 같을때$\\mathit{f}(t) = \\mathit{f}_1(t)\\hat{i}\\,+\\,\\mathit{f}_2(t)\\hat{j}+\\,\\mathit{f}_3(t)\\hat{k}$(여기서 $\\mathit{f_1},\\,\\mathit{f_2},\\,\\mathit{f_3}$은 각 기저 상의 좌표)이를 시간에 대해 미분하면,$ \\begin{align} \\frac{d}{dt}\\mathit{f} &amp;amp;= \\frac{d\\mathit{f_1}}{dt}\\hat{i} + \\frac{d\\hat{i}}{dt}\\mathit{f_1} +\\frac{d\\mathit{f_2}}{dt}\\hat{j} + \\frac{d\\hat{j}}{dt}\\mathit{f_2} +\\frac{d\\mathit{f_3}}{dt}\\hat{k} + \\frac{d\\hat{k}}{dt}\\mathit{f_3} \\\\&amp;amp;= \\frac{d\\mathit{f_1}}{dt}\\hat{i} + \\frac{d\\mathit{f_2}}{dt}\\hat{j} + \\frac{d\\mathit{f_3}}{dt}\\hat{k} + [\\Omega\\times(\\mathit{f_1}\\hat{i}+\\mathit{f_2}\\hat{j}+\\mathit{f_3}\\hat{k})] \\\\&amp;amp;= \\bigl(\\frac{d\\mathit{f}}{dt}\\bigr)_r + \\Omega \\times \\mathit{f}\\end{align} $여기서 $ \\bigl(\\frac{d\\mathit{f}}{dt}\\bigr)_r $는 회전 좌표계상의 $\\mathit{f}_n$ 변화율을 의미함.$\\mathit{f}\\,$의 길이가 고정이라면 $ \\bigl(\\frac{d\\mathit{f}}{dt}\\bigr)_r = 0 $ConclusionRotataion frame상의 고정 길이 벡터의 시간에 대한 미분은 그 고정 길이 벡터와 각 속도의 외적이다.\\(C = \\overrightarrow{p} + R\\overrightarrow{r}\\)\\(\\frac{d(C)}{dt} = \\overrightarrow{v} + w \\times\\overrightarrow{r}\\)Referencehttps://en.wikipedia.org/wiki/Rotating_reference_frame" }, { "title": "Pairing function, 짝짓기 함수", "url": "/posts/pairing-function/", "categories": "Programming, Note", "tags": "Math", "date": "2022-01-04 21:53:00 +0900", "snippet": "Paring functionhttps://en.wikipedia.org/wiki/Pairing_function#Cantor_pairing_function자연수 두 개를 한 개로 맵핑하는 함수.자연수 두 개를 key로 하여 새로운 key를 만들고자 할 때 써먹을 수 있다.\\[\\pi: \\mathbb{N} \\times \\mathbb{N} \\to \\mathbb{N}\\]\\[\\pi(a, b) = \\frac{(a + b)(a + b + 1)}{2} + b\\,(where\\,a,\\,b \\in \\mathbb{N})\\]역변환도 가능하다.역변환시 인자 순서가 보장된다.\\[p = \\pi(a,\\,b)\\]\\[w = [\\frac{\\sqrt{8p+1} - 1}{2}]\\]\\[t = \\frac{w^2 + w}{2}\\]\\[b = p - t\\]\\[a = w - b\\]Code아래는 타입스크립트 코드.// Author Sopiro(https://github.com/Sopiro)export interface Pair&amp;lt;A, B&amp;gt;{ p1: A, p2: B,}// Cantor pairing function, ((N, N) -&amp;gt; N) mapping function// https://en.wikipedia.org/wiki/Pairing_function#Cantor_pairing_functionexport function make_pair_natural(a: number, b: number): number{ return (a + b) * (a + b + 1) / 2 + b;}// Reverse version of pairing function// this guarantees initial pairing orderexport function separate_pair(p: number): Pair&amp;lt;number, number&amp;gt;{ let w = Math.floor((Math.sqrt(8 * p + 1) - 1) / 2.0); let t = (w * w + w) / 2.0; let y = p - t; let x = w - y; return { p1: x, p2: y };}아래와 같은 형식으로 맵핑된다고 한다." }, { "title": "첫 개발 블로그", "url": "/posts/%EC%B2%AB-%EA%B0%9C%EB%B0%9C-%EB%B8%94%EB%A1%9C%EA%B7%B8/", "categories": "일상", "tags": "잡담", "date": "2022-01-03 23:38:00 +0900", "snippet": "기록을 남기자최근 공부, 개발하면서 찾아본 내용들을 기록으로 남기고자 하는 욕구가 샘솟는 와중이었다.jekyll 템플릿을 둘러보는데 지금 사용하는 chirpy라는 깔끔하고 좋은 템플릿을 발견하여 바로 시작하게 됐다!Jekyll, chirpy 특징마크다운 형식으로 글을 작성할 수 있고 카테고리, 태그별로 게시글 검색이 가능하다.게시글 오른편에 목차가 마크다운 h태그에 맞춰서 자동으로 생성된다.disqus, utterances 모듈을 이용해 간단히 댓글기능도 구현 가능하다.MathJax라는 자바스크립트 기반 수식 엔진 이용해 수식도 이용 가능하다!(수식을 우클릭하면 컨텍스트 메뉴가 떠서 원글을 복사 할 수있다)\\[P_c = J^T \\lambda\\]\\[\\lambda = (J M^{-1} J^T)^{-1} \\cdot -(JV + b)\\]그리고 무엇보다 chirpy 테마는 있을 기능만 딱 있고 인터페이스가 친숙해서 좋다.다짐앞으로는 자료 찾으면 북마크만 해놓지말고 대충이라도 기록으로 남기자!" } ]
